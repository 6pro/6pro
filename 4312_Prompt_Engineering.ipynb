{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/6pro/6pro/blob/main/4312_Prompt_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EECS 4312 Lab 9 - Prompt Engineering using GPT-3.5\n",
        "## Author - Faiz Ahmed, EXINES lab, York University"
      ],
      "metadata": {
        "id": "5DTr9SrkV0ou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "Prompt engineering is a crucial skill in the era of large language models (LLMs). Just as data scientists need clean data for analysis, AI practitioners need well-crafted prompts to get optimal results from LLMs. This skill involves understanding how to effectively communicate with AI models to achieve desired outcomes, whether it's generating code, analyzing text, or solving complex problems.\n",
        "In this tutorial, we'll learn how to craft effective prompts using the OpenAI API. We'll explore various techniques from basic prompting to advanced methods like chain-of-thought reasoning and few-shot learning. While these examples won't cover every possible prompting technique, they'll provide you with a solid foundation for developing your own prompting strategies. We'll focus on two main approaches: direct prompting and context-enhanced prompting.\n",
        "\n",
        "## Prerequisites\n",
        "1. Python Programming Basics\n",
        "\n",
        "    * Understanding of Python syntax\n",
        "    * Familiarity with functions and loops\n",
        "    * Basic error handling concepts\n",
        "\n",
        "\n",
        "2. Development Environment\n",
        "\n",
        "    * Jupyter Notebooks or Google Colab (Lab 1 of EECS 4312)\n",
        "    * OpenAI API key (sign up at platform.openai.com)\n",
        "\n",
        "\n",
        "3. Required Python Packages\n",
        "\n",
        "    * openai\n",
        "    * json (for handling API responses)\n",
        "\n",
        "\n",
        "4. Concepts to Know\n",
        "\n",
        "    * Basic JSON structure\n",
        "    * API fundamentals\n",
        "    * Simple string manipulation"
      ],
      "metadata": {
        "id": "g2CIMj-rWGrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective\n",
        "\n",
        "In this notebook, you'll learn advanced prompt engineering techniques for ChatGPT and how to effectively communicate with Large Language Models (LLMs) to get optimal responses.\n",
        "\n",
        "This notebook explores various prompting techniques and their applications:\n",
        "\n",
        "- Zero-shot prompting: Direct instructions without examples\n",
        "- Few-shot prompting: Using examples to guide responses\n",
        "- Chain-of-thought prompting: Breaking down complex reasoning\n",
        "- Role-based prompting: Setting context through expertise"
      ],
      "metadata": {
        "id": "0KXekCO4XLbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### install the openai library"
      ],
      "metadata": {
        "id": "Uw6WxTvwa-al"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0c7ocQgTl0f",
        "outputId": "432dff48-c0aa-4624-f6d9-e09f7b73f239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ],
      "source": [
        "%pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import the libraries"
      ],
      "metadata": {
        "id": "uZbkYHggbGCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "from time import sleep"
      ],
      "metadata": {
        "id": "PTMA8RvNX-8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set up OpenAI client with API key stored in Google Colab's secrets\n",
        "##### This is a secure way to store and access your API key in Colab\n",
        "##### Steps to add your API key to Colab secrets:\n",
        "##### 1. Click on the \"üîë\" icon in the left sidebar\n",
        "##### 2. Click on \"Add new secret\"\n",
        "##### 3. Set name as \"openai_api\" and paste your OpenAI API key as the value\n",
        "##### 4. The key will persist across sessions but remains secure and hidden"
      ],
      "metadata": {
        "id": "yHlIBCngbKyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "client = OpenAI(api_key=userdata.get('openai_api'))"
      ],
      "metadata": {
        "id": "CMr-0kfTXUpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### OpenAI Chat Completion Function\n",
        "\n",
        "##### **Overview**\n",
        "The `get_completion` function is a utility wrapper for OpenAI's chat completion API. It simplifies the process of getting responses from models like GPT-3.5-turbo by handling the API call and error management."
      ],
      "metadata": {
        "id": "1pKc0JQ1be1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0):\n",
        "    \"\"\"\n",
        "    Get a response from OpenAI's chat model.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): Input text to send to model\n",
        "        model (str, optional): OpenAI model name. Default: \"gpt-3.5-turbo\"\n",
        "        temperature (float, optional): Response randomness (0-1). Default: 0\n",
        "\n",
        "    Returns:\n",
        "        str: Model's response text, or None if error occurs\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Make API call to OpenAI's chat completion endpoint\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,           # Specify which model to use (e.g., gpt-3.5-turbo)\n",
        "            messages=[             # Format prompt as a message array\n",
        "                {\n",
        "                    \"role\": \"user\",    # Set message role as user\n",
        "                    \"content\": prompt  # The actual prompt text\n",
        "                }\n",
        "            ],\n",
        "            temperature=temperature    # Control response randomness (0=focused, 1=creative)\n",
        "        )\n",
        "        # Extract and return just the message content from the first response\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        # Handle any API errors and print the error message\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "MMUVnWZQYClO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Zero-Shot Prompting\n",
        "##### Below is an example of zero-shot prompting, where you don't provide any examples to the LLM within the prompt itself."
      ],
      "metadata": {
        "id": "w9Luz0wDcPAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Zero-Shot Prompting\n",
        "zero_shot_prompt = \"\"\"\n",
        "Classify the sentiment of this tweet as positive, negative, or neutral:\n",
        "\n",
        "Tweet: \"Just finished watching the latest Marvel movie. Completely exceeded my expectations!\"\n",
        "Sentiment:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "x8734ARbZ9KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One-Shot Prompting\n",
        "##### Below is an example of one-shot prompting, where you provide one example to the LLM within the prompt to give some guidance on what type of response you want."
      ],
      "metadata": {
        "id": "SOgZ6TECcYdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. One-Shot Prompting\n",
        "one_shot_prompt = \"\"\"\n",
        "Classify the sentiment of tweets as positive, negative, or neutral.\n",
        "\n",
        "Tweet: \"The weather is perfect today! ‚òÄÔ∏è\"\n",
        "Sentiment: positive\n",
        "\n",
        "Tweet: \"This new restaurant downtown is way too expensive for what they serve.\"\n",
        "Sentiment:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3ALUIcLqZ_Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Few-Shot Prompting\n",
        "##### Below is an example of few-shot prompting, where you provide a few examples to the LLM within the prompt to give some guidance on what type of response you want.\n",
        "\n"
      ],
      "metadata": {
        "id": "jmTEX46CcgI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Few-Shot Prompting\n",
        "few_shot_prompt = \"\"\"\n",
        "Classify the sentiment of tweets as positive, negative, or neutral.\n",
        "\n",
        "Tweet: \"Can't wait for the weekend!\"\n",
        "Sentiment: positive\n",
        "\n",
        "Tweet: \"The train is delayed again... üò§\"\n",
        "Sentiment: negative\n",
        "\n",
        "Tweet: \"Just had my morning coffee.\"\n",
        "Sentiment: neutral\n",
        "\n",
        "Tweet: \"This phone's battery life is terrible and the camera is even worse!\"\n",
        "Sentiment:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "KzGIhV3paBqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chain-Of-Thought Prompting\n",
        "##### Below is an example of Chain-Of-Thought prompting where you break down complex problems into step-by-step reasoning to improve accuracy and transparency."
      ],
      "metadata": {
        "id": "tu94CR6Ncnwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Chain of Thought Prompting\n",
        "chain_of_thought_prompt = \"\"\"\n",
        "Analyze the sentiment of this tweet by breaking down the emotional elements and context, then provide a final classification as positive, negative, or neutral.\n",
        "\n",
        "Tweet: \"The price of this laptop is high, but the performance and build quality make it worth every penny. Really happy with my purchase despite the cost!\"\n",
        "\n",
        "Let's think about this step by step:\n",
        "1. Identify key phrases and their sentiment:\n",
        "2. Consider any contrasting elements:\n",
        "3. Evaluate overall context:\n",
        "4. Make final classification:\n",
        "\n",
        "Final Sentiment:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "giY_dCnTaGOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Role-Based Few-Shot\n",
        "##### Below is an example of Role-Based prompting where you  assign a specific role or expertise to the LLM to get specialized or contextually appropriate responses."
      ],
      "metadata": {
        "id": "r_sFpp9MdPrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Role-Based Few-Shot\n",
        "role_based_prompt = \"\"\"\n",
        "You are an expert data analyst. Classify these customer comments into specific categories and provide a brief explanation why.\n",
        "\n",
        "Comment: \"Website loads too slowly\"\n",
        "Category: Technical Issue\n",
        "Explanation: Relates to system performance and user experience\n",
        "\n",
        "Comment: \"Great customer service team!\"\n",
        "Category: Service Feedback\n",
        "Explanation: Direct praise for support staff performance\n",
        "\n",
        "Comment: \"The mobile app keeps freezing when I try to checkout\"\n",
        "Category:\n",
        "Explanation:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "bF6wMbydaJQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to test all prompts\n",
        "def test_prompts():\n",
        "    prompts = {\n",
        "        \"Zero-Shot\": zero_shot_prompt,\n",
        "        \"One-Shot\": one_shot_prompt,\n",
        "        \"Few-Shot\": few_shot_prompt,\n",
        "        \"Chain of Thought\": chain_of_thought_prompt,\n",
        "        \"Role-Based\": role_based_prompt\n",
        "    }\n",
        "\n",
        "    for name, prompt in prompts.items():\n",
        "        print(f\"\\n=== {name} Prompting ===\")\n",
        "        print(\"Prompt:\")\n",
        "        print(prompt)\n",
        "        print(\"\\nResponse:\")\n",
        "        response = get_completion(prompt)\n",
        "        print(response)\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        sleep(1)  # Rate limiting"
      ],
      "metadata": {
        "id": "WyY1XQUbY6XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_prompts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVaHGsaDaQMx",
        "outputId": "d588bc79-13d7-4736-f5e4-9ce0ec375ce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Zero-Shot Prompting ===\n",
            "Prompt:\n",
            "\n",
            "Classify the sentiment of this tweet as positive, negative, or neutral:\n",
            "\n",
            "Tweet: \"Just finished watching the latest Marvel movie. Completely exceeded my expectations!\"\n",
            "Sentiment:\n",
            "\n",
            "\n",
            "Response:\n",
            "Positive\n",
            "\n",
            "==================================================\n",
            "\n",
            "=== One-Shot Prompting ===\n",
            "Prompt:\n",
            "\n",
            "Classify the sentiment of tweets as positive, negative, or neutral.\n",
            "\n",
            "Tweet: \"The weather is perfect today! ‚òÄÔ∏è\"\n",
            "Sentiment: positive\n",
            "\n",
            "Tweet: \"This new restaurant downtown is way too expensive for what they serve.\"\n",
            "Sentiment:\n",
            "\n",
            "\n",
            "Response:\n",
            "negative\n",
            "\n",
            "==================================================\n",
            "\n",
            "=== Few-Shot Prompting ===\n",
            "Prompt:\n",
            "\n",
            "Classify the sentiment of tweets as positive, negative, or neutral.\n",
            "\n",
            "Tweet: \"Can't wait for the weekend!\"\n",
            "Sentiment: positive\n",
            "\n",
            "Tweet: \"The train is delayed again... üò§\"\n",
            "Sentiment: negative\n",
            "\n",
            "Tweet: \"Just had my morning coffee.\"\n",
            "Sentiment: neutral\n",
            "\n",
            "Tweet: \"This phone's battery life is terrible and the camera is even worse!\"\n",
            "Sentiment:\n",
            "\n",
            "\n",
            "Response:\n",
            "negative\n",
            "\n",
            "==================================================\n",
            "\n",
            "=== Chain of Thought Prompting ===\n",
            "Prompt:\n",
            "\n",
            "Analyze the sentiment of this tweet by breaking down the emotional elements and context, then provide a final classification as positive, negative, or neutral.\n",
            "\n",
            "Tweet: \"The price of this laptop is high, but the performance and build quality make it worth every penny. Really happy with my purchase despite the cost!\"\n",
            "\n",
            "Let's think about this step by step:\n",
            "1. Identify key phrases and their sentiment:\n",
            "2. Consider any contrasting elements:\n",
            "3. Evaluate overall context:\n",
            "4. Make final classification:\n",
            "\n",
            "Final Sentiment:\n",
            "\n",
            "\n",
            "Response:\n",
            "Overall, the sentiment of this tweet is positive. The key phrases \"worth every penny\" and \"Really happy with my purchase\" indicate satisfaction and contentment with the laptop despite its high price. The contrasting element of the high price is acknowledged but ultimately outweighed by the positive aspects of the laptop's performance and build quality. The context suggests that the individual feels that the benefits of the laptop justify the cost, leading to a positive sentiment overall.\n",
            "\n",
            "==================================================\n",
            "\n",
            "=== Role-Based Prompting ===\n",
            "Prompt:\n",
            "\n",
            "You are an expert data analyst. Classify these customer comments into specific categories and provide a brief explanation why.\n",
            "\n",
            "Comment: \"Website loads too slowly\"\n",
            "Category: Technical Issue\n",
            "Explanation: Relates to system performance and user experience\n",
            "\n",
            "Comment: \"Great customer service team!\"\n",
            "Category: Service Feedback\n",
            "Explanation: Direct praise for support staff performance\n",
            "\n",
            "Comment: \"The mobile app keeps freezing when I try to checkout\"\n",
            "Category:\n",
            "Explanation:\n",
            "\n",
            "\n",
            "Response:\n",
            "Category: Technical Issue\n",
            "Explanation: Indicates a problem with the functionality of the mobile app, potentially related to bugs or compatibility issues.\n",
            "\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### References\n",
        "\n",
        "1. ##### Prompt Engineering Guide: https://www.promptingguide.ai/\n",
        "2. ##### OpenAI page: https://platform.openai.com/apps\n",
        "3. ##### Youtube tutorial for Prompt Engineering: https://www.youtube.com/watch?v=_ZvnD73m40o\n",
        "4. ##### Academic Paper: https://www.techrxiv.org/doi/full/10.36227/techrxiv.22683919.v2"
      ],
      "metadata": {
        "id": "L7ob1Pp0b34K"
      }
    }
  ]
}